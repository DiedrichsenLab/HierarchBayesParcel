{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Quick test of different ways of estimating Kappas across subejcts and parcels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "import os\n",
    "import sys \n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy,deepcopy\n",
    "\n",
    "import HierarchBayesParcel.emissions as em\n",
    "import HierarchBayesParcel.arrangements as ar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make some artifical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_subj = 4\n",
    "P = 1000\n",
    "N = 10\n",
    "K = 5\n",
    "U = pt.randint(low=0, high=K, size=(n_subj, P))\n",
    "U_hat = ar.expand_mn(U,K)\n",
    "emission_model = em.MixVMF(K, N, P, n_subj)\n",
    "emission_model.kappa=pt.tensor(20)\n",
    "Y = emission_model.sample(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = deepcopy(emission_model)\n",
    "m.random_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do an M-step by hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "JU = pt.sum(U_hat,dim=2)   # (num_sub, K)\n",
    " # Calculate YU = \\sum_i\\sum_k<u_i^k>y_i # (num_sub, N, K)\n",
    "YU = pt.matmul(Y, pt.transpose(U_hat, 1, 2)) \n",
    "\n",
    "# If the subjects are weighted differently\n",
    "r_norm2 = pt.sum(YU ** 2, dim=1, keepdim=True) # (num_sub, 1, K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7905, 0.7955, 0.7899, 0.7989, 0.8020],\n",
       "        [0.7998, 0.7952, 0.8021, 0.7979, 0.7967],\n",
       "        [0.7877, 0.7896, 0.8044, 0.7955, 0.7940],\n",
       "        [0.8002, 0.8098, 0.7962, 0.7996, 0.7997]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.sqrt(r_norm2.squeeze())/JU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7940, 0.7970, 0.7973, 0.7970, 0.7973]])\n"
     ]
    }
   ],
   "source": [
    "# Overall V estimation\n",
    "V = pt.sum(YU,dim=0) / JU.sum(dim=0, keepdim=True)\n",
    "print(pt.sqrt(pt.sum(V**2, dim=0, keepdim=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7938, 0.7970, 0.7974, 0.7971, 0.7974]])\n"
     ]
    }
   ],
   "source": [
    "# Subject-equal weighting V estimation\n",
    "V=pt.nanmean(YU / JU.unsqueeze(1),dim=0)\n",
    "print(pt.sqrt(pt.sum(V**2, dim=0, keepdim=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7965) tensor(20.4098)\n"
     ]
    }
   ],
   "source": [
    "# Overall kappa \n",
    "yu = pt.sum(YU,dim=0)\n",
    "r=pt.sum(pt.sqrt(pt.sum(yu**2, dim=0)))/ pt.sum(JU)\n",
    "kappa = (r*N - r**3) / (1 - r**2)\n",
    "print(r, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7955, 0.7984, 0.7941, 0.8011]) tensor([20.2941, 20.6166, 20.1457, 20.9284])\n"
     ]
    }
   ],
   "source": [
    "# Subject-specific kappa\n",
    "r = pt.sum(pt.sqrt(pt.sum(YU**2, dim=1)),dim=1)/pt.sum(JU,dim=1)\n",
    "kappa = (r*N - r**3) / (1 - r**2)\n",
    "print(r, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7940, 0.7970, 0.7973, 0.7970, 0.7973]) tensor([20.1350, 20.4602, 20.4958, 20.4650, 20.4911])\n"
     ]
    }
   ],
   "source": [
    "# Region-specfic kappa\n",
    "yu = pt.sum(YU,dim=0)\n",
    "r=pt.sqrt(pt.sum(yu**2, dim=0))/ pt.sum(JU,dim=0)\n",
    "kappa = (r*N - r**3) / (1 - r**2)\n",
    "print(r, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region and subject-specific kappa \n",
    "r=pt.sqrt(pt.sum(YU**2, dim=1))/ JU\n",
    "kappa = (r*N - r**3) / (1 - r**2)\n",
    "print(r, kappa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
